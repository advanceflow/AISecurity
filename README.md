# 格式
会议或期刊名缩写＋年份＋题目
# 内容

1.  [数据](#09381cd)
2.  [模型](#b537b8d)
3.  [评估](#432eb28)
4.  [安全](#3a196a8)
5.  [系统](#e0fe622)


<a id="09381cd"></a>

# 数据


<a id="b537b8d"></a>

# 模型


<a id="432eb28"></a>

# 评估


<a id="3a196a8"></a>

# 安全


<a id="e0fe622"></a>

# 系统

# 简介
| 内容                                                                                                                                   | 简介             |
|----------------------------------------------------------------------------------------------------------------------------------------|------------------|
| ACL2023-Backdooring Neural Code Search                                                                                                 | 后门攻击         |
| ACL2023-Sentence Embedding Leaks More Information than You Expect  Generative Embedding Inversion Attack to Recover the Whole Sentence | 数据恢复         |
| CVPR2023-Defending against Adversarial Audio via Diffusion Model                                                                       | 对抗攻击         |
| CVPR2023-TrojDiff  Trojan Attacks on Diffusion Models with Diverse Targets                                                             | 对抗攻击         |
| ICLR2022-Robust Learning Meets Generative Models  Can Proxy Distributions Improve Adversarial Robustness                               | 对抗攻击＋稳定性 |
| ICLR2023-DensePure  Understanding Diffusion Models towards Adversarial Robustness                                                      | 对抗攻击＋稳定性 |
| ICLR2023-Prompting GPT-3 To Be Reliable                                                                                                | 模型稳定性       |
| ICML2021-Adversarial Purification with Score-based Generative Models                                                                   | 对抗攻击         |
| ICML2022-Diffusion Models for Adversarial Purification                                                                                 | 对抗性净化       |
| ICML2023-Better Diffusion Models Further Improve Adversarial Training                                                                  | 对抗性训练       |
| ICML2023-Improving Adversarial Robustness by Contrastive Guided Diffusion Process                                                      | 对抗稳定性       |
| ICML2023-Poisoning Language Models During Instruction Tuning                                                                           | 投毒攻击         |
| NDSS2023-BadGPT  Exploring Security Vulnerabilities of ChatGPT via Backdoor Attacks to InstructGPT                                     | 后门攻击         |
| UCENIX2023-DiffSmooth  Certifiably Robust Learning via Diffusion Models and Local Smoothing                                            | 稳定性           |
| USENIX2021-Extracting Training Data from Large Language Models                                                                         | 数据恢复         |
	
